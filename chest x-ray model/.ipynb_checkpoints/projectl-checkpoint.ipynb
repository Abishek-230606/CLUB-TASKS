{
 "cells": [
  {
   "cell_type": "raw",
   "id": "70e4357b-86f5-469c-a3a0-1beb10a347ba",
   "metadata": {},
   "source": [
    "# STEP 1 IMPORT ALL THE LIBRARY REQURIED\n",
    "1.ImageDataGenerator → loads and preprocesses images.\n",
    "\n",
    "2.Sequential + layers → build CNN model.\n",
    "\n",
    "3.EarlyStopping, ModelCheckpoint → stop overfitting and save best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9465a-2639-4545-adaf-8960904d61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf6ed7-79c0-4ee6-9795-8a930e76fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 — Load your dataset with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4034cbe-109f-4536-8efc-7bcfa6a75fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Paths to your dataset folders\n",
    "train_dir = \"dataset/train\"\n",
    "val_dir   = \"dataset/val\"\n",
    "test_dir  = \"dataset/test\"\n",
    "\n",
    "# Rescale pixel values (0–255 → 0–1)\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training set\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),   # resize all images\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"       # because only 2 classes\n",
    ")\n",
    "\n",
    "# Load validation set\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# Load test set\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False   # don’t shuffle, useful for evaluation\n",
    ")\n",
    "\n",
    "print(\"Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b94dd4-070d-4e85-8daf-7c128414184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-3 building your CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b14ae-96ca-4aa6-83ef-28266b750912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c473c7-ef88-43be-a481-d7bb7a93ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)  # resizing\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03c5ec-009a-42d4-b2e4-8d5f9c2e9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the splits (prevent leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc70f42-d892-405a-87d8-b4329cd95c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_dir:\", train_dir)\n",
    "print(\"val_dir:\",   val_dir)\n",
    "print(\"test_dir:\",  test_dir)\n",
    "\n",
    "print(\"Train samples:\", train_gen.samples)\n",
    "print(\"Val samples:\",   val_gen.samples)\n",
    "print(\"Test samples:\",  test_gen.samples)\n",
    "\n",
    "# Ensure only test_gen has shuffle=False\n",
    "train_gen.shuffle = True\n",
    "val_gen.shuffle = True\n",
    "test_gen.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc565ca1-22e5-4758-b642-21933495d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the cnn model for training the model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95f22d5d-a892-41d6-8386-952760c3b3a5",
   "metadata": {},
   "source": [
    "#What This Model Does\n",
    "| Layer | Purpose | \n",
    "| Conv2D | Extracts features from the image (edges, textures) | \n",
    "| MaxPooling2D | Reduces spatial size, keeps important features | \n",
    "| Flatten | Converts 2D feature maps into 1D vector | \n",
    "| Dense | Fully connected layer for classification | \n",
    "| Dropout | Prevents overfitting by randomly turning off neurons | \n",
    "| Softmax | Outputs probabilities for each class (Normal vs TB) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdd95d-f2b7-4320-a151-2c148e6d54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define image size and input shape\n",
    "img_size = 224  # Same as used in preprocessing\n",
    "input_shape = (img_size, img_size, 3)  # RGB images\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    # First convolutional block\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Second convolutional block\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Third convolutional block\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Helps prevent overfitting\n",
    "    Dense(2, activation='softmax')  # 2 output classes: Normal and Tuberculosis\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c768fd4-490f-4fc8-b76e-8e07bd2d0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Train the model using your train_data and val_data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc90f5c-aad0-4dac-a8ed-f187fdf0edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, epochs=10, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6daad26-f343-4b67-8f33-64756f28abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021797d-2920-4b82-a671-0e63f090acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(val_gen)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc8f1b-fcd5-4952-8e1a-83e2e09edd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abd93a-3eb0-4a97-ae66-f3d9a6e21ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = val_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d34cd-d330-4c95-aecf-85f065fe4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136470c4-866b-449c-91e6-7212faa3d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_gen)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89685760-477b-419a-b5d4-12babde8c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22479ce-6011-4450-9d4a-dcbca3fe1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e430dba-ef21-40f1-8b6a-b67a77987c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f462de-8b0a-4a63-a87d-31a2bdd9ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
