{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2ba2f0",
   "metadata": {},
   "source": [
    "1. Importing Required Libraries:\n",
    "\n",
    "We start by importing the essential Python libraries for image processing, model building, training, and evaluation. These libraries include TensorFlow/Keras for deep learning, NumPy for numerical operations, Matplotlib for plotting, and scikit-learn for evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42345953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437d95b",
   "metadata": {},
   "source": [
    "2. Setting Up Dataset Paths and Parameters:\n",
    "\n",
    "We specify the paths to our dataset folders and set the image size and batch size. The dataset is organized into training, validation, and test folders. Each of these contains three subfolders: Normal, Tuberculosis, and Pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd59bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset/train\"\n",
    "val_dir   = \"dataset/val\"\n",
    "test_dir  = \"dataset/test\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031b519",
   "metadata": {},
   "source": [
    "3. Creating Image Data Generators:\n",
    "\n",
    "We use ImageDataGenerator to preprocess the images. For training data, we apply augmentation techniques such as rotation and zoom to improve generalization. For validation and test data, we only rescale pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13874af8",
   "metadata": {},
   "source": [
    " 4. Loading the Datases:\n",
    "\n",
    " We load the images from the folders with the data generators. We resize the images to 224x224 and group them by class labels. We set shuffle=False for the test set to ensure consistent evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd76586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450bf55b",
   "metadata": {},
   "source": [
    "5. Building the CNN Model:[IMPORTANT AND CRUTIAL STEP]\n",
    "\n",
    "We build a Convolutional Neural Network (CNN) using Keras. The model consists of three convolutional layers that \n",
    "extract features. \n",
    "These are followed by dense layers for classification.\n",
    "The final layer uses softmax activation to provide probabilities for three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # 3 classes: Normal, TB, Pneumonia\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba69be7",
   "metadata": {},
   "source": [
    "6. Compiling the ModeL:[HELPS IN MODEL TRAINING AND OUTPUT]\n",
    "\n",
    "We build the model with the Adam optimizer and categorical cross-entropy loss. This setup works well for multi-class classification. We also monitor accuracy as a performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3156a8",
   "metadata": {},
   "source": [
    "7. Training the ModeL:\n",
    "\n",
    "We train the model with the training data and check it using the validation set. We train for 10 epochs to see how learning progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8aa6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, epochs=10, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0494cb8",
   "metadata": {},
   "source": [
    "8. Evaluating the Model  \n",
    "  \n",
    "We check the model on the validation set to see how well it performs. We also make predictions on the test set and compare these predictions with the actual labels using a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(val_gen)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "predictions = model.predict(test_gen)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dcfdd",
   "metadata": {},
   "source": [
    "9. Visualizing Training Accuracy\n",
    "\n",
    "We plot the training and validation accuracy over epochs to show how well the model is learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30f294-8a48-4520-9988-cf9d90927a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
